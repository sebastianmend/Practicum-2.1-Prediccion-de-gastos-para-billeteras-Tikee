{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente.\n",
      "Mapa interactivo guardado en: mapa_transacciones.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Ruta al archivo JSON\n",
    "file_path = \"dataset/transacciones_actualizadas.json\"\n",
    "\n",
    "# Cargar el JSON como lista\n",
    "try:\n",
    "    df = pd.read_json(file_path)  # No usar `lines=True`\n",
    "    print(\"Datos cargados exitosamente.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error al cargar el archivo JSON: {e}\")\n",
    "    raise\n",
    "\n",
    "# Verificar si el dataset tiene datos\n",
    "if df.empty:\n",
    "    raise ValueError(\"El archivo JSON no contiene datos o está vacío.\")\n",
    "\n",
    "# Crear un mapa centrado en las coordenadas promedio del dataset\n",
    "centro_latitud = df[\"latitud\"].mean()\n",
    "centro_longitud = df[\"longitud\"].mean()\n",
    "mapa = folium.Map(location=[centro_latitud, centro_longitud], zoom_start=12)\n",
    "\n",
    "# Añadir marcadores para cada transacción en el dataset\n",
    "for _, fila in df.iterrows():\n",
    "    popup_info = f\"<b>ID Transacción:</b> {fila['id_transaccion']}<br>\" \\\n",
    "                 f\"<b>Monto:</b> {fila['monto']}<br>\" \\\n",
    "                 f\"<b>Ordenante:</b> {fila['ordenante_nombre_completo']}<br>\" \\\n",
    "                 f\"<b>Beneficiario:</b> {fila['beneficiario_nombre_completo']}\"\n",
    "\n",
    "    folium.Marker(\n",
    "        location=[fila[\"latitud\"], fila[\"longitud\"]],\n",
    "        popup=folium.Popup(popup_info, max_width=300),\n",
    "        icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
    "    ).add_to(mapa)\n",
    "\n",
    "# Guardar el mapa en un archivo HTML\n",
    "output_path = \"mapa_transacciones.html\"\n",
    "mapa.save(output_path)\n",
    "print(f\"Mapa interactivo guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento y normalizacion del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset transformado con columnas originales de latitud y longitud:\n",
      "   ordenante_cedula    latitud   longitud      local_nombre  latitud_original  \\\n",
      "0        3597400581 -12.046357 -77.042883       Desconocido        -12.046357   \n",
      "1        3597400581 -12.046464 -77.042727       Desconocido        -12.046464   \n",
      "2        3597400581 -12.046440 -77.042898       Desconocido        -12.046440   \n",
      "3        3597400581  -3.995926 -79.204172  Bogati Heladeria         -3.995926   \n",
      "4        3597400581  -4.007181 -79.203194       Magic Retro         -4.007181   \n",
      "\n",
      "   longitud_original  hora  dia_semana  local_nombre_encoded  \n",
      "0         -77.042883     2           6                     3  \n",
      "1         -77.042727     0           2                     3  \n",
      "2         -77.042898    15           3                     3  \n",
      "3         -79.204172     7           3                     0  \n",
      "4         -79.203194    18           3                     7  \n",
      "Dataset transformado guardado en: dataset/transacciones_transformadas.json\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset desde un archivo JSON\n",
    "file_path = r\"dataset/transacciones_actualizadas.json\"\n",
    "df = pd.read_json(file_path)\n",
    "\n",
    "# Filtrar las columnas relevantes\n",
    "variables_interes = [\"ordenante_cedula\", \"latitud\", \"longitud\", \"fecha_hora\", \"local_nombre\"]\n",
    "df = df[variables_interes]\n",
    "\n",
    "# Completar valores faltantes en 'local_nombre'\n",
    "df[\"local_nombre\"] = df[\"local_nombre\"].fillna(\"Desconocido\")\n",
    "\n",
    "# Guardar las columnas originales de latitud y longitud\n",
    "df[\"latitud_original\"] = df[\"latitud\"]\n",
    "df[\"longitud_original\"] = df[\"longitud\"]\n",
    "\n",
    "# Extraer hora y día de la semana de 'fecha_hora'\n",
    "df[\"hora\"] = pd.to_datetime(df[\"fecha_hora\"]).dt.hour\n",
    "df[\"dia_semana\"] = pd.to_datetime(df[\"fecha_hora\"]).dt.weekday\n",
    "\n",
    "# Eliminar la columna original 'fecha_hora' ya que ahora está representada\n",
    "df = df.drop(columns=[\"fecha_hora\"])\n",
    "\n",
    "# Codificar 'local_nombre' con LabelEncoder para convertirlo en una variable numérica\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"local_nombre_encoded\"] = label_encoder.fit_transform(df[\"local_nombre\"])\n",
    "\n",
    "# Mostrar el dataset transformado\n",
    "print(\"Dataset transformado con columnas originales de latitud y longitud:\")\n",
    "print(df.head())\n",
    "\n",
    "# Guardar el dataset transformado\n",
    "output_path = \"dataset/transacciones_transformadas.json\"\n",
    "df.to_json(output_path, orient=\"records\", lines=True)\n",
    "print(f\"Dataset transformado guardado en: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir el dataset para entrenamiento y para testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de entrenamiento guardado en: dataset/transacciones_train.json\n",
      "Dataset de testeo guardado en: dataset/transacciones_test.json\n",
      "Ejemplo del dataset de entrenamiento:\n",
      "     ordenante_cedula    latitud   longitud      local_nombre  \\\n",
      "100        4557997274  -3.995926 -79.204172  Bogati Heladeria   \n",
      "101        4557997274 -12.046304 -77.042721       Desconocido   \n",
      "102        4557997274 -12.046434 -77.042738       Desconocido   \n",
      "103        4557997274 -12.046445 -77.042892       Desconocido   \n",
      "104        4557997274 -12.046400 -77.042766       Desconocido   \n",
      "\n",
      "     latitud_original  longitud_original  hora  dia_semana  \\\n",
      "100         -3.995926         -79.204172    10           1   \n",
      "101        -12.046304         -77.042721     1           1   \n",
      "102        -12.046434         -77.042738     9           0   \n",
      "103        -12.046445         -77.042892    21           5   \n",
      "104        -12.046400         -77.042766     4           0   \n",
      "\n",
      "     local_nombre_encoded  \n",
      "100                     0  \n",
      "101                     3  \n",
      "102                     3  \n",
      "103                     3  \n",
      "104                     3  \n",
      "\n",
      "Ejemplo del dataset de testeo:\n",
      "   ordenante_cedula    latitud   longitud      local_nombre  latitud_original  \\\n",
      "0        3597400581 -12.046357 -77.042883       Desconocido        -12.046357   \n",
      "1        3597400581 -12.046464 -77.042727       Desconocido        -12.046464   \n",
      "2        3597400581 -12.046440 -77.042898       Desconocido        -12.046440   \n",
      "3        3597400581  -3.995926 -79.204172  Bogati Heladeria         -3.995926   \n",
      "4        3597400581  -4.007181 -79.203194       Magic Retro         -4.007181   \n",
      "\n",
      "   longitud_original  hora  dia_semana  local_nombre_encoded  \n",
      "0         -77.042883     2           6                     3  \n",
      "1         -77.042727     0           2                     3  \n",
      "2         -77.042898    15           3                     3  \n",
      "3         -79.204172     7           3                     0  \n",
      "4         -79.203194    18           3                     7  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "    # Cargar el dataset transformado\n",
    "file_path = \"dataset/transacciones_transformadas.json\"\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "# Dividir los datos por usuario (ordenante_cedula)\n",
    "usuarios = df[\"ordenante_cedula\"].unique()\n",
    "\n",
    "# Crear conjuntos de usuarios para entrenamiento y testeo\n",
    "usuarios_train, usuarios_test = train_test_split(\n",
    "        usuarios, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Separar el dataset en base a los usuarios seleccionados\n",
    "df_train = df[df[\"ordenante_cedula\"].isin(usuarios_train)]\n",
    "df_test = df[df[\"ordenante_cedula\"].isin(usuarios_test)]\n",
    "\n",
    "    # Guardar los datasets en archivos separados\n",
    "train_path = \"dataset/transacciones_train.json\"\n",
    "test_path = \"dataset/transacciones_test.json\"\n",
    "\n",
    "df_train.to_json(train_path, orient=\"records\", lines=True)\n",
    "df_test.to_json(test_path, orient=\"records\", lines=True)\n",
    "\n",
    "    # Imprimir mensajes de confirmación\n",
    "print(f\"Dataset de entrenamiento guardado en: {train_path}\")\n",
    "print(f\"Dataset de testeo guardado en: {test_path}\")\n",
    "\n",
    "    # Verificar las divisiones con ejemplos\n",
    "print(\"Ejemplo del dataset de entrenamiento:\")\n",
    "print(df_train.head())\n",
    "print(\"\\nEjemplo del dataset de testeo:\")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de Modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='euclidean', n_neighbors=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib\n",
    "\n",
    "# Cargar el dataset transformado y normalizado\n",
    "train_path = \"dataset/transacciones_train.json\"\n",
    "df_train = pd.read_json(train_path, lines=True)\n",
    "\n",
    "# Definir los pesos para las características\n",
    "pesos = {\n",
    "    \"latitud\": 0.3,\n",
    "    \"longitud\": 0.3,\n",
    "    \"hora\": 0.3,\n",
    "    \"dia_semana\": 0.1\n",
    "}\n",
    "\n",
    "# Aplicar los pesos a las características normalizadas\n",
    "for columna, peso in pesos.items():\n",
    "    df_train[columna] *= peso\n",
    "\n",
    "# Seleccionar las características para entrenar el modelo\n",
    "X_train = df_train[[\"latitud\", \"longitud\", \"hora\", \"dia_semana\"]]\n",
    "\n",
    "# Entrenar el modelo KNN\n",
    "modelo_knn = NearestNeighbors(n_neighbors=10, metric=\"euclidean\")\n",
    "modelo_knn.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo KNN entrenado y guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "joblib.dump(modelo_knn, \"recomendador_knn.pkl\")\n",
    "\n",
    "print(\"Modelo KNN entrenado y guardado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para Recomendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendaciones finales:\n",
      "            local_nombre  latitud_original  longitud_original  hora  \\\n",
      "0       Bogati Heladeria         -3.995926         -79.204172    10   \n",
      "37  Manantial restaurant         -4.000665         -79.201764    10   \n",
      "48           Magic Retro         -4.007181         -79.203194    10   \n",
      "41   Las Papas del hueco         -3.994721         -79.202306    11   \n",
      "31        Chifa Oriental         -4.000614         -79.204941    11   \n",
      "\n",
      "    dia_semana  distancia_haversine  \n",
      "0            1             0.000032  \n",
      "37           3             0.588340  \n",
      "48           3             1.249289  \n",
      "41           3             0.246393  \n",
      "31           3             0.525382  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Practicum2.1\\venv\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Pesos para las características (aplicados antes de usar KNN)\n",
    "pesos = {\n",
    "    \"latitud\": 0.3,\n",
    "    \"longitud\": 0.3,\n",
    "    \"hora\": 0.3,\n",
    "    \"dia_semana\": 0.1\n",
    "}\n",
    "\n",
    "# Cargar el modelo KNN previamente entrenado\n",
    "modelo_knn = joblib.load(\"recomendador_knn.pkl\")\n",
    "\n",
    "def recomendar_por_cedula(cedula, cliente, radio_haversine=10.0, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Realiza recomendaciones basadas en el historial de transacciones del usuario.\n",
    "    :param cedula: Cédula del usuario.\n",
    "    :param cliente: Lista con las características del cliente (latitud, longitud, hora, día de la semana).\n",
    "    :param radio_haversine: Radio en kilómetros para filtrar recomendaciones.\n",
    "    :param n_neighbors: Número de vecinos a considerar con KNN.\n",
    "    :return: Recomendaciones de comercios dentro del radio.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargar el dataset de entrenamiento\n",
    "        train_path = \"dataset/transacciones_train.json\"\n",
    "        df_train = pd.read_json(train_path, lines=True)\n",
    "\n",
    "        # Filtrar el historial del usuario por cédula\n",
    "        historial_usuario = df_train[df_train[\"ordenante_cedula\"] == cedula]\n",
    "        if historial_usuario.empty:\n",
    "            print(f\"No se encontró historial para el usuario con cédula: {cedula}\")\n",
    "            return None\n",
    "\n",
    "        # Aplicar los pesos a los datos del cliente\n",
    "        cliente_datos = [\n",
    "            cliente[0] * pesos[\"latitud\"],\n",
    "            cliente[1] * pesos[\"longitud\"],\n",
    "            cliente[2] * pesos[\"hora\"],\n",
    "            cliente[3] * pesos[\"dia_semana\"]\n",
    "        ]\n",
    "\n",
    "        # Obtener los vecinos más cercanos utilizando KNN\n",
    "        X_train = historial_usuario[[\"latitud\", \"longitud\", \"hora\", \"dia_semana\"]].copy()\n",
    "        for columna, peso in pesos.items():\n",
    "            X_train[columna] *= peso\n",
    "        modelo_knn.fit(X_train)  # Entrenar el modelo con el historial del usuario\n",
    "        distancias, indices = modelo_knn.kneighbors([cliente_datos], n_neighbors=n_neighbors)\n",
    "\n",
    "        # Recuperar las recomendaciones iniciales\n",
    "        recomendaciones = historial_usuario.iloc[indices[0]].copy()\n",
    "\n",
    "        # Calcular la distancia Haversine utilizando las columnas originales\n",
    "        cliente_coords = (cliente[0], cliente[1])  # Coordenadas originales del cliente\n",
    "        recomendaciones[\"distancia_haversine\"] = recomendaciones.apply(\n",
    "            lambda row: geodesic(\n",
    "                (row[\"latitud_original\"], row[\"longitud_original\"]),\n",
    "                cliente_coords\n",
    "            ).kilometers,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Filtrar las recomendaciones dentro del radio Haversine\n",
    "        recomendaciones_filtradas = recomendaciones[recomendaciones[\"distancia_haversine\"] <= radio_haversine]\n",
    "\n",
    "        if recomendaciones_filtradas.empty:\n",
    "            print(f\"No se encontraron recomendaciones dentro del radio de {radio_haversine} km.\")\n",
    "            return None\n",
    "\n",
    "        # Retornar las recomendaciones finales\n",
    "        return recomendaciones_filtradas[[\n",
    "            \"local_nombre\", \"latitud_original\", \"longitud_original\", \n",
    "            \"hora\", \"dia_semana\", \"distancia_haversine\"\n",
    "        ]]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en la función de recomendación: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Datos del cliente: características originales\n",
    "cedula_cliente = 4557997274\n",
    "cliente_datos = [-3.995926, -79.204172, 10, 1]  # Coordenadas originales y contexto del cliente\n",
    "\n",
    "# Radio Haversine en kilómetros\n",
    "radio_haversine = 10\n",
    "\n",
    "# Realizar la recomendación\n",
    "recomendaciones = recomendar_por_cedula(cedula_cliente, cliente_datos, radio_haversine=radio_haversine)\n",
    "\n",
    "# Imprimir las recomendaciones\n",
    "if recomendaciones is not None:\n",
    "    print(\"Recomendaciones finales:\")\n",
    "    print(recomendaciones)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
